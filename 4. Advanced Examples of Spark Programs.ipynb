{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09e4ad55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warning: there was one unchecked warning; for details, enable `:setting -unchecked' or `:replay -unchecked'\n",
       "defined class Movie\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Most watched movie\n",
    "\n",
    "final case class Movie(userID: Int, movieID: Int, rating:Int,timestamp:Long )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6c522cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userID|movieID|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|     3|881250949|\n",
      "|   186|    302|     3|891717742|\n",
      "|    22|    377|     1|878887116|\n",
      "|   244|     51|     2|880606923|\n",
      "|   166|    346|     1|886397596|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-----+\n",
      "|movieID|count|\n",
      "+-------+-----+\n",
      "|     50|  583|\n",
      "|    258|  509|\n",
      "|    100|  508|\n",
      "|    181|  507|\n",
      "|    294|  485|\n",
      "|    286|  481|\n",
      "|    288|  478|\n",
      "|      1|  452|\n",
      "|    300|  431|\n",
      "|    121|  429|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, IntegerType, LongType}\n",
       "ds: org.apache.spark.sql.Dataset[Movie] = [userID: int, movieID: int ... 2 more fields]\n",
       "topMovies: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [movieID: int, count: bigint]\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, IntegerType, LongType}\n",
    "val ds = spark.read\n",
    ".option(\"sep\", \"\\t\")\n",
    ".schema(\n",
    "    new StructType()\n",
    "    .add(\"userID\", IntegerType, nullable= true)\n",
    "    .add(\"movieID\", IntegerType, nullable= true)\n",
    "    .add(\"rating\", IntegerType, nullable= true)\n",
    "    .add(\"timestamp\", LongType, nullable = true)\n",
    ")\n",
    ".csv(\"data/ml-100k/u.data\")\n",
    ".as[Movie]\n",
    "\n",
    "ds.show(5)\n",
    "\n",
    "val topMovies = ds.groupBy(\"movieID\").count().orderBy(desc(\"count\"))\n",
    "\n",
    "topMovies.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cebed882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userID|movieID|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|     3|881250949|\n",
      "|   186|    302|     3|891717742|\n",
      "|    22|    377|     1|878887116|\n",
      "|   244|     51|     2|880606923|\n",
      "|   166|    346|     1|886397596|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import scala.io.{Codec, Source}\n",
       "import org.apache.spark.sql.functions.{col, udf}\n",
       "loadMovieNames: ()Map[Int,String]\n",
       "nameDict: org.apache.spark.broadcast.Broadcast[Map[Int,String]] = Broadcast(117)\n",
       "ds: org.apache.spark.sql.Dataset[Movie] = [userID: int, movieID: int ... 2 more fields]\n",
       "movieCounts: org.apache.spark.sql.DataFrame = [movieID: int, count: bigint]\n",
       "lookupName: Int => String = $Lambda$4633/0x00000008418ed040@2ad2766c\n",
       "lookupNameUDF: org.apache.spark.sql.expressions.UserDefinedFunction = SparkUserDefinedFunction($Lambda$4633/0x00000008418ed040@2ad2766c,StringType,List(Some(class[value[0]: int])),Some(class[value[0]: string]),None,true,true)\n",
       "movieCountsWithName: org.apache.spark.sql.DataFrame = [movieID: int, count: bigint ... 1 more field]\n",
       "topMovies: org.apache.spark.sql.Dataset[o...\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//-----------------------------------------------------------------\n",
    "// Join movie name: faslt lookup using in memory broadcasted map\n",
    "import scala.io.{Codec, Source}\n",
    "import org.apache.spark.sql.functions.{col, udf}\n",
    "\n",
    "def loadMovieNames(): Map[Int, String] = {\n",
    "    // Codec of the file\n",
    "    implicit val codec = Codec(\"ISO-8859-1\")\n",
    "    \n",
    "    var movieNames:Map[Int,String] = Map()\n",
    "    \n",
    "    // Load the Map with the content of the file\n",
    "    val lines = Source.fromFile(\"data/ml-100k/u.item\")\n",
    "    for (line <- lines.getLines()){\n",
    "        val fields = line.split(\"|\")\n",
    "        if(fields.length > 1){\n",
    "            movieNames += (fields(0).toInt -> fields(1))\n",
    "        }\n",
    "    }\n",
    "    lines.close()\n",
    "    movieNames\n",
    "}\n",
    "\n",
    "val nameDict = sc.broadcast(loadMovieNames())\n",
    "\n",
    "val ds = spark.read\n",
    ".option(\"sep\", \"\\t\")\n",
    ".schema(\n",
    "    new StructType()\n",
    "    .add(\"userID\", IntegerType, nullable= true)\n",
    "    .add(\"movieID\", IntegerType, nullable= true)\n",
    "    .add(\"rating\", IntegerType, nullable= true)\n",
    "    .add(\"timestamp\", LongType, nullable = true)\n",
    ")\n",
    ".csv(\"data/ml-100k/u.data\")\n",
    ".as[Movie]\n",
    "\n",
    "ds.show(5)\n",
    "\n",
    "val movieCounts = ds.groupBy(\"movieID\").count()\n",
    "\n",
    "// User Defined Function\n",
    "val lookupName : Int => String = (movieId:Int) => {\n",
    "    nameDict.value(movieId)\n",
    "}\n",
    "\n",
    "// Wrap it with a UDF\n",
    "val lookupNameUDF = udf(lookupName)\n",
    "\n",
    "// Add movie title from the lookup table\n",
    "val movieCountsWithName = movieCounts.withColumn(\"movieTitle\",lookupNameUDF(col(\"movieId\")) )\n",
    "\n",
    "val topMovies = movieCountsWithName.sort(desc(\"count\"))\n",
    "\n",
    "//topMovies.show(5) // Exception =/\n",
    "println(topMovies.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3d2647fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class MovieRating\n",
       "defined class MovieItem\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//-----------------------------------------------------------------\n",
    "// Let's try the above with joins\n",
    "case class MovieRating(movieID: Int)\n",
    "case class MovieItem(movieID: Int, movieTitle:String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1e5d038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|movieID|\n",
      "+-------+\n",
      "|    242|\n",
      "|    302|\n",
      "|    377|\n",
      "|     51|\n",
      "|    346|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-----------------+\n",
      "|movieID|       movieTitle|\n",
      "+-------+-----------------+\n",
      "|      1| Toy Story (1995)|\n",
      "|      2| GoldenEye (1995)|\n",
      "|      3|Four Rooms (1995)|\n",
      "|      4|Get Shorty (1995)|\n",
      "|      5|   Copycat (1995)|\n",
      "+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+--------------------+------------+\n",
      "| ID|          Movie Name|# of Ratings|\n",
      "+---+--------------------+------------+\n",
      "| 50|    Star Wars (1977)|         583|\n",
      "|258|      Contact (1997)|         509|\n",
      "|100|        Fargo (1996)|         508|\n",
      "|181|Return of the Jed...|         507|\n",
      "|294|    Liar Liar (1997)|         485|\n",
      "|286|English Patient, ...|         481|\n",
      "|288|       Scream (1996)|         478|\n",
      "|  1|    Toy Story (1995)|         452|\n",
      "|300|Air Force One (1997)|         431|\n",
      "|121|Independence Day ...|         429|\n",
      "+---+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, IntegerType, LongType, StringType}\n",
       "ds: org.apache.spark.sql.Dataset[MovieRating] = [movieID: int]\n",
       "dsTitle: org.apache.spark.sql.Dataset[MovieItem] = [movieID: int, movieTitle: string]\n",
       "topMovies: org.apache.spark.sql.DataFrame = [ID: int, Movie Name: string ... 1 more field]\n"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, IntegerType, LongType, StringType}\n",
    "val ds = spark.read\n",
    ".option(\"sep\", \"\\t\")\n",
    ".schema(\n",
    "    new StructType()\n",
    "    .add(\"userID\", IntegerType, nullable= true)\n",
    "    .add(\"movieID\", IntegerType, nullable= true)\n",
    "    .add(\"rating\", IntegerType, nullable= true)\n",
    "    .add(\"timestamp\", LongType, nullable = true)\n",
    ")\n",
    ".csv(\"data/ml-100k/u.data\")\n",
    ".select(\"movieID\")\n",
    ".as[MovieRating]\n",
    "\n",
    "ds.show(5)\n",
    "\n",
    "val dsTitle = spark.read\n",
    ".option(\"sep\", \"|\")\n",
    ".schema(\n",
    "    new StructType()\n",
    "    .add(\"movieID\", IntegerType, nullable= true)\n",
    "    .add(\"movieTitle\", StringType, nullable= true)\n",
    "    .add(\"releaseDate\", StringType, nullable= true)\n",
    "    .add(\"empty\", StringType, nullable= true)\n",
    "    .add(\"url\", StringType, nullable= true)\n",
    ")\n",
    ".csv(\"data/ml-100k/u.item\")\n",
    ".select(\"movieID\", \"movieTitle\")\n",
    ".as[MovieItem]\n",
    "\n",
    "dsTitle.show(5)\n",
    "\n",
    "val topMovies = ds.groupBy(\"movieID\").count()\n",
    ".join(dsTitle, \"movieId\")\n",
    ".sort(desc(\"count\"))\n",
    ".select(\n",
    "    col(\"movieID\").alias(\"ID\"),\n",
    "    col(\"movieTitle\").alias(\"Movie Name\"),\n",
    "    col(\"count\").alias(\"# of Ratings\")\n",
    ")\n",
    "\n",
    "topMovies.show(10)\n",
    "\n",
    "//val dsJoin = ds.join(dsTitle, \"movieId\")\n",
    "//dsJoin.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b707ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
