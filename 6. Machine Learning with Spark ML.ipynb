{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e598fb",
   "metadata": {},
   "source": [
    "# Spark ML\n",
    "\n",
    "Main capabilities\n",
    "\n",
    "* Feature extraction\n",
    "* Basic statistics\n",
    "* Linear ; logistic regression\n",
    "* SVM\n",
    "* Naive Bayes classifier\n",
    "* Decision trees\n",
    "* K-Means clustering\n",
    "* PCA, SVD\n",
    "* ALS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef7ea0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.recommendation._\n",
       "import org.apache.spark.sql.{Row, SparkSession}\n",
       "import org.apache.spark.sql.types.{IntegerType, LongType, StringType, StructType}\n",
       "import scala.collection.mutable\n",
       "defined class MoviesNames\n",
       "defined class Rating\n",
       "getMovieName: (movieNames: Array[MoviesNames], movieId: Int)String\n",
       "runASL: (args: Array[String])Unit\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Using ASL for movie recommendations\n",
    "\n",
    "import org.apache.spark.ml.recommendation._\n",
    "import org.apache.spark.sql.{Row, SparkSession}\n",
    "import org.apache.spark.sql.types.{IntegerType, LongType, StringType, StructType}\n",
    "import scala.collection.mutable\n",
    "\n",
    "case class MoviesNames(movieId: Int, movieTitle: String)\n",
    "  // Row format to feed into ALS\n",
    "  case class Rating(userID: Int, movieID: Int, rating: Float)\n",
    "\n",
    "  // Get movie name by given dataset and id\n",
    "  def getMovieName(movieNames: Array[MoviesNames], movieId: Int): String = {\n",
    "    val result = movieNames.filter(_.movieId == movieId)(0)\n",
    "\n",
    "    result.movieTitle\n",
    "  }\n",
    "\n",
    "def runASL(args:Array[String]){\n",
    "    println(\"Loading movie names...\")\n",
    "    // Create schema when reading u.item\n",
    "    val moviesNamesSchema = new StructType()\n",
    "      .add(\"movieID\", IntegerType, nullable = true)\n",
    "      .add(\"movieTitle\", StringType, nullable = true)\n",
    "\n",
    "    // Create schema when reading u.data\n",
    "    val moviesSchema = new StructType()\n",
    "      .add(\"userID\", IntegerType, nullable = true)\n",
    "      .add(\"movieID\", IntegerType, nullable = true)\n",
    "      .add(\"rating\", IntegerType, nullable = true)\n",
    "      .add(\"timestamp\", LongType, nullable = true)\n",
    "\n",
    "    import spark.implicits._\n",
    "    // Create a broadcast dataset of movieID and movieTitle.\n",
    "    // Apply ISO-885901 charset\n",
    "    val names = spark.read\n",
    "      .option(\"sep\", \"|\")\n",
    "      .option(\"charset\", \"ISO-8859-1\")\n",
    "      .schema(moviesNamesSchema)\n",
    "      .csv(\"data/ml-100k/u.item\")\n",
    "      .as[MoviesNames]\n",
    "\n",
    "    val namesList = names.collect()\n",
    "\n",
    "    // Load up movie data as dataset\n",
    "    val ratings = spark.read\n",
    "      .option(\"sep\", \"\\t\")\n",
    "      .schema(moviesSchema)\n",
    "      .csv(\"data/ml-100k/u.data\")\n",
    "      .as[Rating]\n",
    "    \n",
    "    // Build the recommendation model using Alternating Least Squares\n",
    "    println(\"\\nTraining recommendation model...\")\n",
    "    \n",
    "    val als = new ALS()\n",
    "      .setMaxIter(5)\n",
    "      .setRegParam(0.01)\n",
    "      .setUserCol(\"userID\")\n",
    "      .setItemCol(\"movieID\")\n",
    "      .setRatingCol(\"rating\")\n",
    "    \n",
    "    val model = als.fit(ratings)\n",
    "      \n",
    "    // Get top-10 recommendations for the user we specified\n",
    "    val userID:Int = args(0).toInt\n",
    "    val users = Seq(userID).toDF(\"userID\")\n",
    "    val recommendations = model.recommendForUserSubset(users, 10)\n",
    "    \n",
    "    // Display them (oddly, this is the hardest part!)\n",
    "    println(\"\\nTop 10 recommendations for user ID \" + userID + \":\")\n",
    "\n",
    "    for (userRecs <- recommendations) {\n",
    "      val myRecs = userRecs(1) // First column is userID, second is the recs\n",
    "      val temp = myRecs.asInstanceOf[mutable.WrappedArray[Row]] // Tell Scala what it is\n",
    "      for (rec <- temp) {\n",
    "        val movie = rec.getAs[Int](0)\n",
    "        val rating = rec.getAs[Float](1)\n",
    "        val movieName = getMovieName(namesList, movie)\n",
    "        println(movieName, rating)\n",
    "      }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c43fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading movie names...\n",
      "\n",
      "Training recommendation model...\n",
      "\n",
      "Top 10 recommendations for user ID 10:\n",
      "(Pather Panchali (1955),5.948804)\n",
      "(Angel Baby (1995),5.7073555)\n",
      "(Ruling Class, The (1972),5.436703)\n",
      "(Whole Wide World, The (1996),5.302919)\n",
      "(Anna (1996),5.1569395)\n",
      "(Crossfire (1947),5.1378574)\n",
      "(Welcome To Sarajevo (1997),5.0851583)\n",
      "(Aparajito (1956),5.080312)\n",
      "(Primary Colors (1998),5.0385437)\n",
      "(Schindler's List (1993),4.984884)\n"
     ]
    }
   ],
   "source": [
    "runASL(Array(\"10\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
